{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from typing import Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from adase.utils.pandas import read_df\n",
    "from adase.utils.files import (directory_path,\n",
    "                                get_raw_file,\n",
    "                                get_all_files)\n",
    "from adase.utils.pandas import write_df, read_df\n",
    "\n",
    "def config(path) -> Dict:\n",
    "    with open(\"{}config.yml\".format(path), 'r') as ymlfile:\n",
    "            cfg = yaml.load(ymlfile)\n",
    "    return cfg\n",
    "\n",
    "def download_dataset(cfg:Dict):\n",
    "    \n",
    "    raw_path = cfg.get('dataset').get('path_read_input')\n",
    "    for file in tqdm(cfg.get('makedataset').get('files')):\n",
    "        get_raw_file(raw_path, file)\n",
    "\n",
    "def load_dataset(cfg:Dict):\n",
    "    \n",
    "    raw_path = cfg.get('dataset').get('path_read_input')\n",
    "    \n",
    "    dict_data: Dict = dict()\n",
    "\n",
    "    for key, val in read_df(get_all_files(raw_path)).items():\n",
    "\n",
    "        df_tmp = val.rename(columns={\n",
    "                    'item': 'item_code',\n",
    "                    'quantity_ecd': 'quantity',\n",
    "                    'parent_item': 'parent_item_code',\n",
    "                    'parent_quantity_ecd': 'parent_quantity'\n",
    "                })\n",
    "\n",
    "        if 'rpd' in df_tmp:\n",
    "            first_element = sorted(df_tmp['rpd'].unique())[0]\n",
    "            if first_element/1 != 1:\n",
    "                df_tmp['rpd'] = df_tmp['rpd'] - (first_element-1)\n",
    "\n",
    "        dict_data.update({key: df_tmp})\n",
    "                \n",
    "    return dict_data\n",
    "\n",
    "cfg = config('../')\n",
    "download_dataset(cfg)\n",
    "data_dicts = load_dataset(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "T = 40\n",
    "L = 44 # length of time-series\n",
    "N = 600 # dataset size\n",
    "\n",
    "x = np.empty((N, L), 'int64')\n",
    "x[:] = np.array(range(L)) + np.random.randint(-4 * T, 4 * T, N).reshape(N, 1)\n",
    "data = np.sin((x.T / ((np.random.rand(N)**2)*T + 1)).T).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_series = data_dicts.get('demand_out_encoded_stage_3')\\\n",
    ".set_index(['item_code', 'rpd','future_flag'])\\\n",
    ".sort_index().unstack(\"rpd\", fill_value=0).fillna(0).values\n",
    "\n",
    "mu, sigma = 0, 0.1 \n",
    "#[:600]\n",
    "#data = np.log1p(\n",
    "data=    data_series[:] + np.abs(np.random.normal(mu, sigma, size=data_series.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we plot some generated time-series\n",
    "for i in range(5):\n",
    "    plt.figure(figsize=(5, 1))\n",
    "    plt.plot(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "batch_size = 64\n",
    "log_interval = N/600\n",
    "data_tensor = torch.stack([torch.Tensor(x) for x in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataset_train = torch.utils.data.TensorDataset(data_tensor[:int(N*5/6)])\n",
    "ts_dataset_test = torch.utils.data.TensorDataset(data_tensor[int(N*5/6):])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(ts_dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(ts_dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE model\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, K=12, P=5, mp=3, hidden_lsz=2, channels=10, lstm_sz=10):\n",
    "        super(VAE, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=channels, kernel_size=K, padding=P)\n",
    "        self.mp1 = nn.MaxPool1d(kernel_size=mp, stride=mp, return_indices=True)\n",
    "        conv_sz = self.conv1.out_channels * ((L + 1 - (K - 2*P)) // mp)\n",
    "        self.fc21 = nn.Linear(conv_sz, hidden_lsz)\n",
    "        self.fc22 = nn.Linear(conv_sz, hidden_lsz)\n",
    "        self.fc3 = nn.Linear(hidden_lsz, conv_sz)\n",
    "        self.ump4 = nn.MaxUnpool1d(kernel_size=mp, stride=mp)\n",
    "        self.deconv4 = nn.ConvTranspose1d(in_channels=channels, out_channels=1, kernel_size=K, padding=P)\n",
    "        self.polish = nn.LSTM(1, lstm_sz, num_layers=1)\n",
    "        self.fc4 = nn.Linear(lstm_sz, 1)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1, self.mp1_inds = self.mp1(F.relu(self.conv1(x.unsqueeze(1))))\n",
    "        h1 = h1.view(h1.shape[0], -1)\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar) + 1e-5\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = self.ump4(F.relu(self.fc3(z).unsqueeze(1).view(z.shape[0], self.deconv4.in_channels, -1)),\n",
    "                       self.mp1_inds)\n",
    "        h4 = F.relu(self.deconv4(h3))\n",
    "        h4 = h4.transpose(1, 0).transpose(2, 0)\n",
    "        h5, _ = self.polish(h4)\n",
    "        h5 = F.relu(h5)\n",
    "        return self.fc4(h5).transpose(1, 0).squeeze()\n",
    "\n",
    "    def forward(self, x, variational_sample=1):\n",
    "        #print(x.shape)\n",
    "        mu, logvar = self.encode(x.view(-1, L))\n",
    "        for i in range(variational_sample):\n",
    "            z = self.reparameterize(mu, logvar)\n",
    "            recon_x = self.decode(z)\n",
    "            if i == 0:\n",
    "                reconstruction = torch.zeros_like(recon_x)\n",
    "            reconstruction += recon_x\n",
    "        reconstruction /= variational_sample\n",
    "        return reconstruction, mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_component_KLD(mu, logvar):\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return KLD\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    MSE = nn.MSELoss(reduction='sum')(recon_x, x.view(-1, x.shape[1]))\n",
    "\n",
    "    return MSE + loss_component_KLD(mu, logvar)\n",
    "\n",
    "def train(epoch, max_batches=2):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data[0].to(device)\n",
    "        #print('data[0].to(device): {}'.format(data))\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        #print('recon_batch: {}'.format(recon_batch))\n",
    "        #print('data: {}'.format(data[:, :recon_batch.shape[1]]))\n",
    "        loss = loss_function(recon_batch, data[:, :recon_batch.shape[1]], mu, logvar)\n",
    "        loss.backward()\n",
    "        #print('loss: {}'.format(loss))\n",
    "        #sys.exit(0)\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            if batch_idx / log_interval >= max_batches:\n",
    "                break\n",
    "    \n",
    "    train_loss /= ((batch_idx + 1)*batch_size)\n",
    "    return train_loss\n",
    "\n",
    "def save_ts_image_overlap(ts_tensor_1, ts_tensor_2, file_path, nrow=1, h=1, w=3, off_axis=False):\n",
    "    ncol = int(np.ceil(len(ts_tensor_1)/float(nrow)))\n",
    "    plt.figure(figsize=(w*nrow, h*ncol))\n",
    "    for i in range(len(ts_tensor_1)):\n",
    "        plt.subplot(ncol, nrow, i + 1)\n",
    "        plt.plot(ts_tensor_1[i].data.numpy())\n",
    "        plt.plot(ts_tensor_2[i].data.numpy())\n",
    "        if off_axis:\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(file_path, bbox_inches='tight', dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "def test(epoch, output_path, recon_samples=1):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            data = data[0].to(device)\n",
    "            \n",
    "            for r in range(recon_samples):\n",
    "                recon_batch_part, mu, logvar = model(data)\n",
    "                if r == 0:\n",
    "                    recon_batch = recon_batch_part\n",
    "                else:\n",
    "                    recon_batch += recon_batch_part\n",
    "            recon_batch /= recon_samples\n",
    "            \n",
    "            test_loss += loss_function(recon_batch, data[:, :recon_batch.shape[1]], mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n, :recon_batch.shape[1]],\n",
    "                                      recon_batch[:n]])\n",
    "                save_ts_image_overlap(data[:n, :recon_batch.shape[1]], \n",
    "                                      recon_batch[:n],\n",
    "                                      output_path + str(epoch) + '.png', \n",
    "                                      nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 5\n",
    "output_path = '../output/'\n",
    "model = VAE(K=36, P=17, hidden_lsz=latent_dim, channels=10, mp=4, lstm_sz=10).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "print('number of model parameters:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_dataset_test[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    t = train(epoch, max_batches=30)\n",
    "    if epoch % 10 == 0:\n",
    "        train_losses.append(t)\n",
    "        test_losses.append(test(epoch, output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.figure(figsize=(5, 1))\n",
    "    plt.plot(data_series[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def px_graph(z, y):\n",
    "    reuse = len(tf.get_collection(tf.GraphKeys.VARIABLES, scope='px')) > 0\n",
    "    # -- p(x)\n",
    "    with tf.variable_scope('px'):\n",
    "        zy = tf.concat(1, (z, y), name='zy/concat')\n",
    "        h1 = Dense(zy, 512, 'layer1', tf.nn.relu, reuse=reuse)\n",
    "        h2 = Dense(h1, 512, 'layer2', tf.nn.relu, reuse=reuse)\n",
    "        px_logit = Dense(h2, 784, 'logit', reuse=reuse)\n",
    "    return px_logit\n",
    "\n",
    "def px_graph(z, y):\n",
    "    reuse = len(tf.get_collection(tf.GraphKeys.VARIABLES, scope='px')) > 0\n",
    "    # -- p(z)\n",
    "    with tf.variable_scope('pz'):\n",
    "        zm = Dense(y, 64, 'zm', reuse=reuse)\n",
    "        zv = Dense(y, 64, 'zv', tf.nn.softplus, reuse=reuse)\n",
    "    # -- p(x)\n",
    "    with tf.variable_scope('px'):\n",
    "        h1 = Dense(z, 512, 'layer1', tf.nn.relu, reuse=reuse)\n",
    "        h2 = Dense(h1, 512, 'layer2', tf.nn.relu, reuse=reuse)\n",
    "        px_logit = Dense(h2, 784, 'logit', reuse=reuse)\n",
    "    return zm, zv, px_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "x = Placeholder((None, 784), 'x')\n",
    "\n",
    "# binarize data and create a y \"placeholder\"\n",
    "with tf.name_scope('x_binarized'):\n",
    "    xb = tf.cast(tf.greater(x, tf.random_uniform(tf.shape(x), 0, 1)), tf.float32)\n",
    "with tf.name_scope('y_'):\n",
    "    y_ = tf.fill(tf.pack([tf.shape(x)[0], 10]), 0.0)\n",
    "\n",
    "# propose distribution over y    \n",
    "qy_logit, qy = qy_graph(xb)\n",
    "\n",
    "# for each proposed y, infer z and reconstruct x\n",
    "z, zm, zv, px_logit = [[None] * 10 for i in xrange(4)]\n",
    "for i in xrange(10):\n",
    "    with tf.name_scope('graphs/hot_at{:d}'.format(i)):\n",
    "        y = tf.add(y_, Constant(np.eye(10)[i], name='hot_at_{:d}'.format(i)))\n",
    "        z[i], zm[i], zv[i] = qz_graph(xb, y)\n",
    "        px_logit[i] = px_graph(z[i], y)\n",
    "\n",
    "# Aggressive name scoping for pretty graph visualization :P\n",
    "with tf.name_scope('loss'):\n",
    "    with tf.name_scope('neg_entropy'):\n",
    "        nent = -cross_entropy_with_logits(qy_logit, qy)\n",
    "    losses = [None] * 10\n",
    "    for i in xrange(10):\n",
    "        with tf.name_scope('loss_at{:d}'.format(i)):\n",
    "            losses[i] = labeled_loss(xb, px_logit[i], z[i], zm[i], zv[i], Constant(0), Constant(1))\n",
    "    with tf.name_scope('final_loss'):\n",
    "        loss = tf.add_n([nent] + [qy[:, i] * losses[i] for i in xrange(10)])\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "x = Placeholder((None, 784), 'x')\n",
    "\n",
    "# binarize data and create a y \"placeholder\"\n",
    "with tf.name_scope('x_binarized'):\n",
    "    xb = tf.cast(tf.greater(x, tf.random_uniform(tf.shape(x), 0, 1)), tf.float32)\n",
    "with tf.name_scope('y_'):\n",
    "    y_ = tf.fill(tf.pack([tf.shape(x)[0], 10]), 0.0)\n",
    "\n",
    "# propose distribution over y\n",
    "qy_logit, qy = qy_graph(xb)\n",
    "\n",
    "# for each proposed y, infer z and reconstruct x\n",
    "z, zm, zv, zm_prior, zv_prior, px_logit = [[None] * 10 for i in xrange(6)]\n",
    "for i in xrange(10):\n",
    "    with tf.name_scope('graphs/hot_at{:d}'.format(i)):\n",
    "        y = tf.add(y_, Constant(np.eye(10)[i], name='hot_at_{:d}'.format(i)))\n",
    "        z[i], zm[i], zv[i] = qz_graph(xb, y)\n",
    "        zm_prior[i], zv_prior[i], px_logit[i] = px_graph(z[i], y)\n",
    "\n",
    "# Aggressive name scoping for pretty graph visualization :P\n",
    "with tf.name_scope('loss'):\n",
    "    with tf.name_scope('neg_entropy'):\n",
    "        nent = -cross_entropy_with_logits(qy_logit, qy)\n",
    "    losses = [None] * 10\n",
    "    for i in xrange(10):\n",
    "        with tf.name_scope('loss_at{:d}'.format(i)):\n",
    "            losses[i] = labeled_loss(xb, px_logit[i], z[i], zm[i], zv[i], zm_prior[i], zv_prior[i])\n",
    "    with tf.name_scope('final_loss'):\n",
    "        loss = tf.add_n([nent] + [qy[:, i] * losses[i] for i in xrange(10)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
